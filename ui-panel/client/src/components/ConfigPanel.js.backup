import React, { useState } from 'react';
import { 
  Form, 
  Input, 
  InputNumber, 
  Button, 
  Space, 
  Alert,
  Divider,
  Tooltip,
  Tabs,
  Collapse,
  Typography,
  Checkbox,
  Row,
  Col,
  Select,
  AutoComplete
} from 'antd';
import { 
  RocketOutlined, 
  InfoCircleOutlined,
  CheckCircleOutlined,
  ExclamationCircleOutlined,
  CodeOutlined,
  SettingOutlined,
  ThunderboltOutlined,
  LinkOutlined,
  GlobalOutlined,
  LockOutlined,
  DockerOutlined
} from '@ant-design/icons';

const { TextArea } = Input;
const { TabPane } = Tabs;
const { Panel } = Collapse;
const { Link } = Typography;

const ConfigPanel = ({ onDeploy, deploymentStatus }) => {
  const [form] = Form.useForm();
  const [loading, setLoading] = useState(false);
  const [activeTab, setActiveTab] = useState('vllm');
  const [selectedDockerImage, setSelectedDockerImage] = useState('');

  // Docker镜像预设选项
  const dockerImageOptions = [
    {
      value: 'vllm/vllm-openai:latest',
      label: 'vllm/vllm-openai:latest'
    },
    {
      value: 'lmsysorg/sglang:latest',
      label: 'lmsysorg/sglang:latest'
    },
    {
      value: 'vllm/vllm-openai:gptoss',
      label: 'vllm/vllm-openai:gptoss'
    }
  ];

  // 根据Docker镜像获取对应的默认命令
  const getDefaultCommandByImage = (dockerImage) => {
    if (dockerImage.includes('sglang')) {
      return `python3 -m sglang.launch_server \\
--model-path Qwen/Qwen3-0.6B \\
--tp-size 1 \\
--host 0.0.0.0 \\
--port 8000 \\
--trust-remote-code`;
    } else if (dockerImage.includes('gptoss')) {
      return `python3 -m vllm.entrypoints.openai.api_server \\
--model openai/gpt-oss:120b \\
--tensor-parallel-size 2 \\
--host 0.0.0.0 \\
--port 8000 \\
--trust-remote-code`;
    } else {
      // 默认VLLM命令
      return `python3 -m vllm.entrypoints.openai.api_server \\
--model Qwen/Qwen3-0.6B \\
--max-num-seqs 32 \\
--max-model-len 1280 \\
--tensor-parallel-size 1 \\
--host 0.0.0.0 \\
--port 8000 \\
--trust-remote-code`;
    }
  };

  // 处理Docker镜像选择变化
  const handleDockerImageChange = (value) => {
    setSelectedDockerImage(value);
    const newCommand = getDefaultCommandByImage(value);
    form.setFieldsValue({ vllmCommand: newCommand });
  };

  // 校验VLLM/SGLang命令格式
  const validateVllmCommand = (_, value) => {
    if (!value) {
      return Promise.reject(new Error('Please input VLLM/SGLang command!'));
    }

    const cleanCommand = value
      .replace(/\\\s*\n/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();

    // 检查是否以支持的entry point开头
    const validEntryPoints = [
      'python3 -m vllm.entrypoints.openai.api_server',
      'python3 -m sglang.launch_server'
    ];

    const hasValidEntryPoint = validEntryPoints.some(entryPoint => 
      cleanCommand.startsWith(entryPoint)
    );

    if (!hasValidEntryPoint) {
      return Promise.reject(new Error(
        '命令必须以以下之一开头:\n' +
        '• python3 -m vllm.entrypoints.openai.api_server\n' +
        '• python3 -m sglang.launch_server'
      ));
    }

    return Promise.resolve();
  };

  const handleTabChange = (key) => {
    console.log('Tab changed to:', key);
    setActiveTab(key);
    // 清除表单验证错误和重置表单
    form.resetFields();
    form.clearValidate();
    
    // 根据不同标签设置不同的初始值
    if (key === 'ollama') {
      form.setFieldsValue({
        replicas: 1,
        ollamaModelId: 'gpt-oss:20b',
        gpuCount: 1,
        isExternal: true
      });
    } else if (key === 'vllm') {
      form.setFieldsValue({
        replicas: 1,
        isExternal: true
      });
    }
  const handleSubmit = async (values) => {
    console.log('handleSubmit called with values:', values);
    console.log('activeTab:', activeTab);
    setLoading(true);
    try {
      const deploymentConfig = {
        ...values,
        deploymentType: activeTab
      };
      
      console.log('deploymentConfig:', deploymentConfig);
      
      // 如果是VLLM部署，从命令中提取模型ID
      if (activeTab === 'vllm' && values.vllmCommand) {
        const modelId = extractModelIdFromVllmCommand(values.vllmCommand);
        if (modelId) {
          deploymentConfig.modelId = modelId;
        }
      }
      
      console.log('Calling onDeploy with config:', deploymentConfig);
      await onDeploy(deploymentConfig);
      console.log('onDeploy completed successfully');
    } catch (error) {
      console.error('Error in handleSubmit:', error);
    } finally {
      setLoading(false);
    }
  };

  // 从VLLM命令中提取模型ID
  const extractModelIdFromVllmCommand = (command) => {
    try {
      // 清理命令字符串
      const cleanCommand = command
        .replace(/\\\s*\n/g, ' ')  // 处理反斜杠换行
        .replace(/\s+/g, ' ')      // 合并多个空格
        .trim();
      
      // 分割为数组
      const parts = cleanCommand.split(' ').filter(part => part.trim());
      
      // 查找 --model 参数
      const modelIndex = parts.findIndex(part => part === '--model');
      if (modelIndex !== -1 && modelIndex + 1 < parts.length) {
        return parts[modelIndex + 1];
      }
      
      return null;
    } catch (error) {
      console.error('Error extracting model ID from VLLM command:', error);
      return null;
    }
  };


  const getStatusAlert = () => {
    if (!deploymentStatus) return null;
    
    const { status, message } = deploymentStatus;
    
    // 简化成功消息，移除具体的部署类型信息
    let displayMessage = message;
    if (status === 'success' && message.includes('Successfully deployed')) {
      // 提取模型名称和访问类型，移除部署类型
      const modelMatch = message.match(/model: ([^(]+)/);
      const accessMatch = message.match(/\(([^)]+) access\)/);
      
      if (modelMatch && accessMatch) {
        displayMessage = `Successfully deployed model: ${modelMatch[1].trim()} (${accessMatch[1]} access)`;
      } else {
        displayMessage = 'Model deployed successfully';
      }
    }
    
    return (
      <Alert
        message={displayMessage}
        type={status === 'success' ? 'success' : 'error'}
        icon={status === 'success' ? <CheckCircleOutlined /> : <ExclamationCircleOutlined />}
        showIcon
        closable
        style={{ marginBottom: 16 }}
      />
    );
  };

  const defaultVllmCommand = getDefaultCommandByImage('vllm/vllm-openai:latest');

  const VLLMForm = () => (
    <Form
      form={form}
      layout="vertical"
      onFinish={handleSubmit}
      initialValues={{
        replicas: 1,
        isExternal: true
      }}
    >
      <Form.Item
        label={
          <Space>
            Replicas
            <Tooltip title="Number of model replicas to deploy">
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="replicas"
        rules={[
          { required: true, message: 'Please input replicas count!' },
          { type: 'number', min: 1, max: 10, message: 'Replicas must be between 1 and 10' }
        ]}
      >
        <InputNumber 
          min={1} 
          max={10} 
          style={{ width: '100%' }}
          placeholder="Number of replicas"
        />
      </Form.Item>

      <Form.Item
        label={
          <Space>
            <DockerOutlined />
            Docker Image
            <Tooltip title="选择预设镜像或输入自定义镜像地址">
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="dockerImage"
        rules={[{ required: true, message: 'Please select or input docker image!' }]}
      >
        <AutoComplete
          options={dockerImageOptions}
          placeholder="选择预设镜像或输入自定义镜像"
          style={{ fontFamily: 'monospace' }}
          onChange={handleDockerImageChange}
          filterOption={(inputValue, option) =>
            option.value.toLowerCase().includes(inputValue.toLowerCase())
          }
        />
      </Form.Item>

      {/* 可折叠的高级设置 */}
      <Collapse ghost>
        <Panel 
          header={
            <Space>
              <SettingOutlined />
              Advanced Settings
            </Space>
          } 
          key="advanced"
        >
          <Form.Item
            label={
              <Space>
                Hugging Face Token
                <Tooltip title="Optional: Required for private models">
                  <InfoCircleOutlined />
                </Tooltip>
              </Space>
            }
            name="huggingFaceToken"
          >
            <Input.Password 
              placeholder="hf_xxxxxxxxxx (optional)"
              visibilityToggle
            />
          </Form.Item>
        </Panel>
      </Collapse>

      <Form.Item
        label={
          <Space>
            <CodeOutlined />
            vLLM / SGLang Command
            <Tooltip title="Complete vLLM or SGLang command including entrypoint and all parameters">
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="vllmCommand"
        rules={[{ validator: validateVllmCommand }]}
      >
        <TextArea
          rows={8}
          placeholder="选择Docker镜像后会自动填充对应的命令模板，或直接输入自定义命令"
          style={{ fontFamily: 'monospace', fontSize: '12px' }}
        />
      </Form.Item>

      <div style={{ marginBottom: 16, padding: 12, backgroundColor: '#f6f8fa', borderRadius: 6 }}>
        <div style={{ fontSize: '12px', color: '#666', marginBottom: 8 }}>
          <strong>命令格式说明：</strong>
        </div>
        <div style={{ fontSize: '11px', color: '#888', fontFamily: 'monospace' }}>
          • 支持的入口点：<br/>
          &nbsp;&nbsp;- python3 -m vllm.entrypoints.openai.api_server (VLLM)<br/>
          &nbsp;&nbsp;- python3 -m sglang.launch_server (SGLang)<br/>
          • 选择不同Docker镜像会自动切换对应的命令模板<br/>
          • 使用反斜杠 \ 进行换行<br/>
          • 参数格式：--参数名 参数值<br/>
          • 需使用8000端口<br/>
          • 系统会自动解析tensor-parallel-size/tp-size来配置GPU资源
        </div>
      </div>

      {/* 部署选项 */}
      <Row gutter={16} style={{ marginBottom: 16 }}>
        <Col span={12}>
          <Form.Item>
            <Button 
              type="primary" 
              htmlType="submit" 
              loading={loading}
              icon={<RocketOutlined />}
              size="large"
              block
            >
              {loading ? 'Deploying Model...' : 'Deploy Model'}
            </Button>
          </Form.Item>
        </Col>
        <Col span={12}>
          <Form.Item
            name="isExternal"
            valuePropName="checked"
            style={{ marginTop: 8 }}
          >
            <Checkbox>
              <Space>
                <GlobalOutlined />
                <span>External Access</span>
                <Tooltip title="Enable internet-facing LoadBalancer for external access. Uncheck for internal-only access.">
                  <InfoCircleOutlined />
                </Tooltip>
              </Space>
            </Checkbox>
          </Form.Item>
        </Col>
      </Row>
    </Form>
  );

  const OllamaForm = () => (
    <Form
      form={form}
      layout="vertical"
      onFinish={handleSubmit}
      onFinishFailed={(errorInfo) => {
        console.log('Form validation failed:', errorInfo);
      }}
      initialValues={{
        replicas: 1,
        ollamaModelId: 'gpt-oss:20b',
        gpuCount: 1,
        isExternal: true
      }}
    >
      <Form.Item
        label={
          <Space>
            Replicas
            <Tooltip title="Number of model replicas to deploy">
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="replicas"
        rules={[
          { required: true, message: 'Please input replicas count!' },
          { type: 'number', min: 1, max: 10, message: 'Replicas must be between 1 and 10' }
        ]}
      >
        <InputNumber 
          min={1} 
          max={10} 
          style={{ width: '100%' }}
          placeholder="Number of replicas"
        />
      </Form.Item>

      <Form.Item
        label={
          <Space>
            Ollama Model ID
            <Tooltip title={
              <div>
                The model ID that Ollama will pull and run.<br/>
                <Link href="https://ollama.com/search" target="_blank" rel="noopener noreferrer">
                  <LinkOutlined /> Browse available models at ollama.com/search
                </Link>
              </div>
            }>
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="ollamaModelId"
        rules={[{ required: true, message: 'Please input Ollama model ID!' }]}
      >
        <Input
          placeholder="e.g., gpt-oss:20b, llama2:7b, mistral"
          style={{ width: '100%' }}
        />
      </Form.Item>

      <Form.Item
        label={
          <Space>
            GPU Count
            <Tooltip title="Number of GPUs allocated per replica">
              <InfoCircleOutlined />
            </Tooltip>
          </Space>
        }
        name="gpuCount"
        rules={[
          { required: true, message: 'Please input GPU count!' },
          { type: 'number', min: 1, max: 8, message: 'GPU count must be between 1 and 8' }
        ]}
      >
        <InputNumber 
          min={1} 
          max={8} 
          style={{ width: '100%' }}
          placeholder="Number of GPUs per replica"
        />
      </Form.Item>

      <div style={{ marginBottom: 16, padding: 12, backgroundColor: '#f0f9ff', borderRadius: 6 }}>
        <div style={{ fontSize: '12px', color: '#0369a1', marginBottom: 8 }}>
          <strong>Ollama 部署说明：</strong>
        </div>
        <div style={{ fontSize: '11px', color: '#0c4a6e' }}>
          • Ollama会自动拉取指定的模型<br/>
          • 服务将在端口11434上运行<br/>
          • 支持标准的Ollama API格式<br/>
          • 模型会缓存在持久存储中<br/>
          • 部署名称将基于模型ID自动生成
        </div>
      </div>

      {/* 部署选项 */}
      <Row gutter={16} style={{ marginBottom: 16 }}>
        <Col span={12}>
          <Form.Item>
            <Button 
              type="primary" 
              htmlType="submit" 
              loading={loading}
              icon={<ThunderboltOutlined />}
              size="large"
              block
              style={{ backgroundColor: '#059669', borderColor: '#059669' }}
            >
              {loading ? 'Deploying Ollama Model...' : 'Deploy Ollama Model'}
            </Button>
          </Form.Item>
        </Col>
        <Col span={12}>
          <Form.Item
            name="isExternal"
            valuePropName="checked"
            style={{ marginTop: 8 }}
          >
            <Checkbox>
              <Space>
                <GlobalOutlined />
                <span>External Access</span>
                <Tooltip title="Enable internet-facing LoadBalancer for external access. Uncheck for internal-only access.">
                  <InfoCircleOutlined />
                </Tooltip>
              </Space>
            </Checkbox>
          </Form.Item>
        </Col>
      </Row>
    </Form>
  );

  return (
    <div>
      {getStatusAlert()}
      
      <Tabs 
        activeKey={activeTab} 
        onChange={handleTabChange}
        type="card"
        size="small"
      >
        <TabPane 
          tab={
            <Space>
              <CodeOutlined />
              vLLM / SGLang
            </Space>
          } 
          key="vllm"
        >
          <VLLMForm />
        </TabPane>
        
        <TabPane 
          tab={
            <Space>
              <ThunderboltOutlined />
              Ollama
            </Space>
          } 
          key="ollama"
        >
          <OllamaForm />
        </TabPane>
      </Tabs>

      <div style={{ marginTop: 16, fontSize: '12px', color: '#666' }}>
        <strong>Note:</strong> 系统会根据选择的部署类型和访问模式生成相应的Kubernetes配置。
        确保EKS集群有足够的GPU资源。
      </div>
    </div>
  );
};

export default ConfigPanel;
